---
layout: post
title: Notes on Information Theory
date: 2021-02-25
permalink: /:title/
description: "Reflections on Shannon's work"
tags: [math, software engineering]
share: true
published: false
status: ongoing
---


Introduction that I should really write last


## Coding of memoryless sources

Given the definition of entropy of a memoryless source, it can be shown that the avarage number of bits required to 
encode the source is equal to its entropy
<!-- ## Information -->
<!--  -->
<!-- Information is defined as  -->
<!--  -->
<!-- ## Why is Huffmann coding the most efficient  -->
